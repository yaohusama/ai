{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 色彩恒常性\n",
    "\n",
    "光照的问题，属于色彩恒常性，需要用到一种图像预处理算法，色彩平衡，下面的两个信息可以做为了解的起点："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在人体生物学领域中，颜色恒常性是指当照射物体表面的颜色光发生变化时，人们对该物体表面颜色的知觉仍然保持不变的知觉特性。\n",
    "\n",
    "在图像处理科学领域中，基于人眼对景物的认知特点，把图像中背景元素与光照元素分离是解决问题的关键所在。\n",
    "\n",
    "https://baike.baidu.com/item/%E8%89%B2%E5%BD%A9%E6%81%92%E5%B8%B8%E6%80%A7/2420709?fr=aladdin\n",
    "\n",
    "### 色彩恒常性原理\n",
    "\n",
    "人类都有一种不因光源或者外界环境因素而改变对某一个特定物体色彩判断的心理倾向，这种倾向即为色彩恒常性。\n",
    "\n",
    "某一个特定物体，由于环境（尤其特指光照环境）的变化，该物体表面的反射谱会有不同。\n",
    "\n",
    "人类的视觉识别系统能够识别出这种变化，并能够判断出该变化是由光照环境的变化而产生的，当光照变化在一定范围内变动时，人类识别机制会在这一变化范围内认为该物体表面颜色是恒定不变的。 \n",
    "\n",
    "颜色知觉的恒常性与人的生活经验密切相关，一个由于眼疾从未见过红旗的人，在痊愈后的光亮中初次见到红旗，可能确定它是红色的。\n",
    "\n",
    "但是如果他在黑暗处初次见到红旗，就不一定能把它知觉为红色。\n",
    "\n",
    "因此，颜色恒常性是指人对物体颜色的知觉，与人的知识经验、心理倾向有关，不是指物体本身颜色的恒定不变。\n",
    "\n",
    "### 图像颜色\n",
    "\n",
    "#### 背景\n",
    "\n",
    "计算机往往协助人类认知世界，在颜色恒常性这个分支学科中也是这样。\n",
    "\n",
    "在颜色恒常性计算中往往涉及 视觉，模式识别，图像处理等学科。\n",
    "\n",
    "#### 原理\n",
    "\n",
    "基于比尔-朗伯特定律，由两种不同的光照形成的图像可以通过对角矩阵转换（Von Kries模型又作对角模型）。\n",
    "\n",
    "因此，我们只需寻找出原图中的光照即可把原图片经对角矩阵转化为在标准白光（R=G=B=1）下的图片。其转换公式如下：[f0=Di-0 fi]\n",
    "\n",
    "其中f0为结果图像，fi为输入图像，Di-0为输入图像向结果图像转换所需的**3x3对角矩阵，其对角值分别为R、G、B三通道输出光照预估值，与输入图像光照的比值**。\n",
    "\n",
    "通过上面的公式，对于图像颜色恒常性探索的问题就转变为**寻找输入图像光照值**的问题。\n",
    "\n",
    "然而，这是一个不能完美解决的问题，因为仅仅凭借一张没有任何来源的输入图像，并不能精确的标定光照信息，\n",
    "\n",
    "只能**凭借对外界环境的假设来估算光照的数值**。\n",
    "\n",
    "#### 方法\n",
    "\n",
    "#### Max-RGB算法：\n",
    "\n",
    "基于假设光照在图像中RGB通道的最大相应是由一个白点（white patch）引起的。\n",
    "\n",
    "在实际计算中RGB三通道是分开计算，分别求出各通道的最大相应值（像素取最大值），作为入射光照。\n",
    "\n",
    "但此算法因只取一个孤立点的值，对光照的估计局限性太大。\n",
    "\n",
    "#### Grey world算法：\n",
    "\n",
    "基于假设场景内所有物理表面的平均反射是无色差的。\n",
    "\n",
    "在实际的计算中光照的三通道值取图像中的平均值。\n",
    "\n",
    "相比MAX算法，Grey world算法有了更强的适应性，但是对于场景中物体颜色过于单一的情况下，其适应性明显不足。\n",
    "\n",
    "#### Grey Edge算法：\n",
    "\n",
    "随着对颜色恒常性研究的深入，有的研究人员发现，颜色的导数在三围空间分布中呈现椭圆形状，而光照与椭圆的方向一致。\n",
    "\n",
    "基于此种发现建立在**颜色导数空间**的假设被提出：\n",
    "\n",
    "场景内所有物理表面的平均反射的差分是无色差的。\n",
    "\n",
    "**图像的光照颜色同计算输入图像的平均颜色导数得到**。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 光照问题之常见算法比较(附Python代码)\n",
    "\n",
    "https://www.cnblogs.com/wangyong/p/9119394.html\n",
    "\n",
    "### 一、灰度世界算法\n",
    "\n",
    "① 算法原理\n",
    "\n",
    "灰度世界算法以灰度世界假设为基础，该假设认为：\n",
    "\n",
    "对于一幅有着大量色彩变化的图像，**R,G,B三个分量的平均值趋于同一灰度值Gray**。\n",
    "\n",
    "从物理意义上讲，灰色世界法假设自然界景物对于光线的平均反射的均值在总体上是个定值，这个定值近似地为“灰色”。\n",
    "\n",
    "颜色平衡算法将这一假设强制应用于待处理图像，可以从图像中消除环境光的影响，获得原始场景图像。\n",
    "\n",
    "一般有两种方法确定Gray值\n",
    "\n",
    "1) 使用固定值，对于8位的图像(0~255)通常取128作为灰度值\n",
    "\n",
    "**2) 计算增益系数,分别计算三通道的平均值avgR，avgG，avgB**，则：\n",
    "\n",
    "Avg=(avgR+avgG+avgB)/3\n",
    "\n",
    "kr=Avg/avgR , kg=Avg/avgG , kb=Avg/avgB\n",
    "\n",
    "**利用计算出的增益系数，重新计算每个像素值，构成新的图片**\n",
    "\n",
    "② 算法优缺点\n",
    "\n",
    "这种算法简单快速，但是当图像场景颜色并不丰富时，尤其出现**大块单色物体时，该算法常会失效**。\n",
    "\n",
    "③ 算法展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grey_world(nimg):\n",
    "    nimg=nimg.transpose(2,0,1).astype(np.uint32)\n",
    "    avg_B=np.average(nimg[0])\n",
    "    avg_G=np.average(nimg[1])\n",
    "    avg_R=np.average(nimg[2])\n",
    "    avg=(avg_B+avg_G+avg_R)/3\n",
    "    nimg[0]=np.minimum(nimg[0]*(avg/avg_B),255)\n",
    "    nimg[1]=np.minimum(nimg[1]*(avg/avg_G),255)\n",
    "    nimg[2]=np.minimum(nimg[2]*(avg/avg_R),255)\n",
    "    return nimg.transpose(1,2,0).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 第一组图片场景颜色丰富，利用灰度世界假设法校正效果明显；\n",
    " \n",
    " 第二组图片中颜色相对单一，校正效果也不是很理想；这也就导致了‘灰度世界假设算法’无法通用."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二、直方图均衡化\n",
    "\n",
    "① 算法原理\n",
    "\n",
    "直方图均衡化的基本思想是把原始图的直方图变换为均匀分布的形式，\n",
    "\n",
    "这样就增加了象素灰度值的动态范围从而可达到增强图像整体对比度的效果\n",
    "\n",
    "假设，一张图像的直方图如下图(左)所示，均衡化后，图像直方图如下图(右)显示\n",
    "\n",
    "② 算法优缺点\n",
    "\n",
    " 直方图均衡化，一般可用于灰度图像的对比增强（如：人脸阴影部位增强）；\n",
    "\n",
    "如果直接对彩色图像R,G,B三通道分别均衡化后再合并，极容易出现颜色不均、失真等问题，\n",
    "\n",
    "所以，一般会将RGB图像转换到YCrCb空间，对Y通道进行均衡化（Y通道代表亮度成分)\n",
    "\n",
    " ③ 算法展示\n",
    "\n",
    "在python中opencv3提供了能将灰度图直接均衡化的方法:equalizeHist(img),借助这个方法，可以实现彩色图像的均衡化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hisEqulColor(img):  \n",
    "    ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)  \n",
    "    channels = cv2.split(ycrcb)  \n",
    "    cv2.equalizeHist(channels[0], channels[0]) #equalizeHist(in,out)  \n",
    "    cv2.merge(channels, ycrcb)  \n",
    "    img_eq=cv2.cvtColor(ycrcb, cv2.COLOR_YCR_CB2BGR)  \n",
    "    return img_eq \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三、视网膜-大脑皮层(Retinex)增强算法\n",
    "\n",
    "① 算法原理\n",
    "\n",
    " 视网膜-大脑皮层（Retinex）理论认为世界是无色的，人眼看到的世界是光与物质相互作用的结果，\n",
    " \n",
    " 也就是说，映射到人眼中的图像和光的长波（R）、中波（G）、短波（B）以及物体的反射性质有关                                                                  \n",
    "I(x,y)=R(x,y)L(x,y)\n",
    "\n",
    "其中I是人眼中看到的图像，R是物体的反射分量，L是环境光照射分量，(x, y)是二维图像对应的位置\n",
    "\n",
    "它通过估算L来计算R，具体来说，L可以通过高斯模糊和I做卷积运算求得，用公式表示为：\n",
    "\n",
    "log(R)=log(I)-log(L)    L=F * I\n",
    "\n",
    "其中F是高斯模糊的滤波器，“ * ”表示卷积运算\n",
    "\n",
    " []\n",
    "\n",
    "其中σ称为高斯周围空间常数（Gaussian Surround Space Constant），也就是算法中所谓的尺度，对图像处理有比较大的影响，对于二维图像，等于对应位置即：\n",
    "\n",
    "即：一般认为光照分量是原图像经过高斯滤波后的结果\n",
    "\n",
    "\n",
    "② 算法优缺点\n",
    "\n",
    "Retinex算法，从SSR（单尺度Retinex）到MSR（多尺度Retinex）以及到最常用的MSRCR（带颜色恢复的多尺度Retinex）；其中色彩恢复主要目的是来调节由于图像局部区域对比度增强而导致颜色失真的缺陷.\n",
    "\n",
    "先看一组公式：\n",
    "\n",
    "RMSRCR(x,y)'=G⋅RMSRCR(x,y)+b\n",
    "\n",
    "RMSRCR (x,y)=C(x,y)RMSR(x,y)\n",
    "\n",
    "C(x,y)=f[I'(x,y)]=f[I(x,y)/∑I(x,y)]Ci(x,y)=f[Ii′(x,y)]=f[Ii(x,y)∑j=1NIj(x,y)] \n",
    "\n",
    "f[I'(x,y)]=βlog[αI'(x,y)]=β{log[αI'(x,y)]−log[∑I(x,y)]}\n",
    "\n",
    "如果是灰度图像，只需要计算一次即可，如果是彩色图像，如RGB三通道，则每个通道均需要如上进行计算\n",
    "\n",
    "G表示增益Gain（一般取值：5）\n",
    "\n",
    "b表示偏差Offset（一般取值：25）\n",
    "\n",
    "I (x, y)表示某个通道的图像\n",
    "\n",
    "C表示某个通道的彩色回复因子，用来调节3个通道颜色的比例；\n",
    "\n",
    "f(·)表示颜色空间的映射函数；\n",
    "\n",
    "β是增益常数（一般取值:46）；\n",
    "\n",
    "α是受控制的非线性强度(一般取值：125)\n",
    "\n",
    "MSRCR算法利用彩色恢复因子C，调节原始图像中3个颜色通道之间的比例关系，从而把相对较暗区域的信息凸显出来，达到了消除图像色彩失真的缺陷。 处理后的图像局部对比度提高，亮度与真实场景相似，在人们视觉感知下，图像显得更加逼真；但是MSRCR算法处理图像后，像素值一般会出现负值。所以从对数域r(x, y)转换为实数域R(x, y)后，需要通过改变增益Gain，偏差Offset对图像进行修正\n",
    "\n",
    " 关于Retinex算法更多的细节，可以查看https://www.cnblogs.com/wangyong/p/8665434.html [链接已失效]\n",
    " \n",
    "上面的两组图片，可以看到第一组的效果明显，第二组的效果很差；同时可和‘灰度世界算法’的结果进行比较；\n",
    "\n",
    "#### 一般认为，Retinex算法比较适合航空图片的处理，‘去雾’效果显著。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四、自动白平衡(AWB)\n",
    "\n",
    "① 算法原理\n",
    "\n",
    " 用一个简单的概念来解释什么是白平衡：假设，图像中R、G、B最高灰度值对应于图像中的白点，最低灰度值的对应于图像中最暗的点；\n",
    " \n",
    " 其余像素点利用(ax+b)映射函数把彩色图像中R、G、B三个通道内的像素灰度值映射到[0.255]的范围内.\n",
    "\n",
    "**白平衡的本质是让白色的物体在任何颜色的光源下都显示为白色**，这一点对人眼来说很容易办到，因为人眼有自适应的能力，只要光源的色彩不超出一定的限度，就可以自动还原白色。\n",
    "\n",
    "但相机就不同了，无论是图像传感器还是胶卷都会记录光源的颜色，白色的物体就会带上光源的颜色，白平衡所要做的就是把这个偏色去掉。\n",
    "\n",
    "\n",
    "② 算法优缺点\n",
    "\n",
    "自动白平衡是一个很复杂的问题，目前还没有一个万能的方法可以解决所有场景的白平衡问题\n",
    "\n",
    "截止2017年，出现不少利用神经网络实现自动白平衡的算法，也会有专门的文档对这部分进行详细的介绍。\n",
    "\n",
    " \n",
    "③ 算法展示\n",
    "\n",
    "利用Lab颜色空间，对图片进行自动白平衡操作."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whiteBalance(img):\n",
    "    \n",
    "    rows=img.shape[0]\n",
    "    cols=img.shape[1]\n",
    "    \n",
    "    final=cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    avg_a=np.average(final[:,:,1])\n",
    "    avg_b=np.average(final[:,:,2])\n",
    "    \n",
    "    for x in range(final.shape[0]):\n",
    "        for y in range(final.shape[1]):\n",
    "            l,a,b=final[x,y,:]\n",
    "            #fix for cv correction\n",
    "            l *=100/255.0\n",
    "            final[x,y,1]=a-((avg_a-128)*(1/100.0)*1.1)\n",
    "            final[x,y,2]=a-((avg_b-128)*(1/100.0)*1.1)\n",
    "    final=cv2.cvtColor(final,cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，这两组效果图和‘灰度世界假设’算法得出的效果图很类似，主要是因为上述的白平衡算法也是基于‘灰度世界’这个假设下的\n",
    "\n",
    "### 五、自动色彩均衡(ACE)\n",
    "\n",
    "① 算法原理\n",
    "\n",
    "ACE算法源自retinex算法，可以调整图像的对比度，实现人眼色彩恒常性和亮度恒常性，\n",
    "\n",
    "该算法考虑了图像中颜色和亮度的空间位置关系，进行局部特性的自适应滤波，\n",
    "\n",
    "实现具有局部和非线性特征的图像亮度与色彩调整和对比度调整，同时满足灰色世界理论假设和白色斑点假设。\n",
    "\n",
    "第一步：对图像进行色彩／空域调整，完成图像的色差校正，得到空域重构图像；\n",
    "\n",
    "[]\n",
    "\n",
    "式中，Rc 是中间结果，Ic(p)-Ic(j)为两个不同点的亮度差，d(p,j)表示距离度量函数，r(*)为亮度表现函数，需是奇函数；这一步可以适应局部图像对比度，r(*)能够放大较小的差异，并丰富大的差异，根据局部内容扩展或者压缩动态范围。一般得，r(*)为：\n",
    "\n",
    "\n",
    "\n",
    "第二步：对校正后的图像进行动态扩展。ACE算法是对单一色道进行的，对于彩色图片需要对每一个色道分别处理\n",
    "\n",
    "    其中存在一种简单的线性扩展：\n",
    "\n",
    "    R(x)=round[127.5+w*Rc(p)],其中，w表示线段[(0,mc),(255,Mc)]的斜率，且有:\n",
    "\n",
    "    Mc=min[Rc(p)]，Mc=max[Rc(p)]\n",
    "\n",
    " \n",
    "\n",
    " 第三步：利用下面的公式将R(x)展到[0,1]之间，得到增强后的通道\n",
    "\n",
    "  []\n",
    "\n",
    "②算法优缺点\n",
    "\n",
    "ACE的增强效果普遍比retinex好。需要注意的是，ACE中当前像素是与整个图像的其他像素做差分比较，计算复杂度非常非常高，这也是限制它应用的最主要原因。\n",
    "\n",
    "所以，**一般算法中，会通过指定采样数来代替与整副图像的像素点信息进行差分计算,减少运算量，提高效率**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#饱和函数\n",
    "def calc_saturation(diff,slope,limit):\n",
    "    ret=diff*slope\n",
    "    if (ret > limit):\n",
    "        ret=limit\n",
    "    elif(ret<(-limit)):\n",
    "        ret=-limit\n",
    "    return ret\n",
    "\n",
    "def automatic_color_equalization(nimg,slope=10,limit=1000,samples=500):\n",
    "\n",
    "    nimg=nimg.transpose(2,0,1)\n",
    "\n",
    "    #Convert input to an ndarray with column-major memory order(仅仅是地址连续,内容和结构不变)\n",
    "    nimg=np.ascontiguousarray(nimg,dtype=np.uint8)\n",
    "\n",
    "    width=nimg.shape[2]\n",
    "    height=nimg.shape[1]\n",
    "\n",
    "    cary=[]\n",
    "\n",
    "    #随机产生索引\n",
    "    for i in range(0,samples):\n",
    "        _x=random.randint(0,width)%width\n",
    "        _y=random.randint(0,height)%height\n",
    "\n",
    "        dict={\"x\":_x,\"y\":_y}\n",
    "        cary.append(dict)\n",
    "\n",
    "\n",
    "    mat=np.zeros((3,height,width),float)\n",
    "\n",
    "    r_max=sys.float_info.min\n",
    "    r_min=sys.float_info.max\n",
    "\n",
    "    g_max=sys.float_info.min\n",
    "    g_min=sys.float_info.max\n",
    "\n",
    "    b_max=sys.float_info.min\n",
    "    b_min=sys.float_info.max\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            r=nimg[0,i,j]\n",
    "            g=nimg[1,i,j]\n",
    "            b=nimg[2,i,j]\n",
    "\n",
    "            r_rscore_sum=0.0\n",
    "            g_rscore_sum=0.0\n",
    "            b_rscore_sum=0.0\n",
    "            denominator=0.0\n",
    "\n",
    "            for _dict in cary:\n",
    "                _x=_dict[\"x\"]#width\n",
    "                _y=_dict[\"y\"]#height\n",
    "\n",
    "                #计算欧氏距离\n",
    "                dist=np.sqrt(np.square(_x-j)+np.square(_y-i))\n",
    "                if (dist <height/5):\n",
    "                    continue;\n",
    "\n",
    "                _sr=nimg[0,_y,_x]\n",
    "                _sg=nimg[1,_y,_x]\n",
    "                _sb=nimg[2,_y,_x]\n",
    "\n",
    "                r_rscore_sum+=calc_saturation(int(r)-int(_sr),slope,limit)/dist\n",
    "                g_rscore_sum+=calc_saturation(int(g)-int(_sg),slope,limit)/dist\n",
    "                b_rscore_sum+=calc_saturation(int(b)-int(_sb),slope,limit)/dist\n",
    "\n",
    "                denominator+=limit/dist\n",
    "\n",
    "            r_rscore_sum=r_rscore_sum/denominator\n",
    "            g_rscore_sum=g_rscore_sum/denominator\n",
    "            b_rscore_sum=b_rscore_sum/denominator\n",
    "\n",
    "            mat[0,i,j]=r_rscore_sum\n",
    "            mat[1,i,j]=g_rscore_sum\n",
    "            mat[2,i,j]=b_rscore_sum\n",
    "\n",
    "            if r_max<r_rscore_sum:\n",
    "                r_max=r_rscore_sum\n",
    "            if r_min>r_rscore_sum:\n",
    "                r_min=r_rscore_sum\n",
    "\n",
    "            if g_max<g_rscore_sum:\n",
    "                g_max=g_rscore_sum\n",
    "            if g_min>g_rscore_sum:\n",
    "                g_min=g_rscore_sum\n",
    "\n",
    "            if b_max<b_rscore_sum:\n",
    "                b_max=b_rscore_sum\n",
    "            if b_min>b_rscore_sum:\n",
    "                b_min=b_rscore_sum\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            nimg[0,i,j]=(mat[0,i,j]-r_min)*255/(r_max-r_min)\n",
    "            nimg[1,i,j]=(mat[1,i,j]-g_min)*255/(g_max-g_min)\n",
    "            nimg[2,i,j]=(mat[2,i,j]-b_min)*255/(b_max-b_min)\n",
    "\n",
    "    return nimg.transpose(1,2,0).astype(np.uint8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当上面的代码原本全部带上中文空格，我是有多崩溃！！！，一个一个改过来的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f45cbb3a4b59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#单尺度Retinex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msingleScaleRetinex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#按照公式计算\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#单尺度Retinex\n",
    "def singleScaleRetinex(img, sigma):\n",
    "    #按照公式计算\n",
    "    _temp=cv2.GaussianBlur(img,(0,0), sigma)\n",
    "    gaussian=np.where(_temp==0, 0.001, _temp)\n",
    "    img_ssr= np.log10(img+0.01) - np.log10(gaussian)\n",
    "    #量化到0--255\n",
    "    for i in range(img_ssr.shape[2]):\n",
    "        img_ssr[:, :, i] = (img_ssr[:,:,i] - np.min(img_ssr[:, :, i])) / \\\n",
    "                (np.max(img_ssr[:,:,i]) - np.min(img_ssr[:, :, i]))*255\n",
    "    img_ssr = np.uint8(np.minimum(np.maximum(img_ssr, 0), 255))\n",
    "    return img_ssr\n",
    "    \n",
    "def singleScaleRetinexTemp(img, sigma):\n",
    "    #按照公式计算\n",
    "    _temp=cv2.GaussianBlur(img,(0,0), sigma)\n",
    "    gaussian=np.where(_temp==0, 0.001, _temp)\n",
    "    retinex = np.log10(img+0.01) - np.log10(gaussian)\n",
    "\n",
    "    return retinex\n",
    "    \n",
    "#多尺度Retinex, sigma_list[15,80,250]\n",
    "def multiScaleRetinex(img, sigma_list):\n",
    "    retinex = np.zeros_like(img*1.0)\n",
    "    for sigma in sigma_list:\n",
    "        print(\"sigma:\", sigma)\n",
    "        retinex += singleScaleRetinexTemp(img, sigma)\n",
    "    img_msr= retinex / len(sigma_list)\n",
    "    for i in range(img_msr.shape[2]):\n",
    "        img_msr[:, :, i] = (img_msr[:,:,i] - np.min(img_msr[:, :, i])) / \\\n",
    "                (np.max(img_msr[:,:,i]) - np.min(img_msr[:, :, i]))*255\n",
    "    img_msr = np.uint8(np.minimum(np.maximum(img_msr, 0), 255))\n",
    "    return img_msr\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    imageSrc = cv2.imread(\"G:\\\\vc2010\\\\Opencv\\\\Test\\\\image\\\\test_MSRCR.jpg\")\n",
    "    cv2.imshow('src',imageSrc)\n",
    "\n",
    "    dstsrc = singleScaleRetinex(imageSrc,300)\n",
    "    cv2.imshow('ssr',dstsrc)\n",
    "    \n",
    "    sigma_list = [15, 80, 250]\n",
    "    dstmsr = multiScaleRetinex(imageSrc, sigma_list)\n",
    "    cv2.imshow('msr',dstmsr) \n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
