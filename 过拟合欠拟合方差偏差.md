# 模型评估与选择
## 欠拟合，过拟合
## 要求
### 对训练数据集有很好拟合（训练误差）
### 未知数据集有很好的拟合结果（泛化能力）
### 
## 欠拟合
### 模型复杂度低，沒学习到规律。
### 解决方法
#### 增加网络复杂度
#### 在模型中增加特征
## 过拟合
### 复杂度高，记住了不合适的特点。泛化能力差
### 原因
#### 训练数据样本单一，样本不足
#### 数据噪声干扰过大
#### 模型特复杂
### 解决：正则化
#### 参数正则化方法
##### L 1正则
##### 
##### L2正则化
###### 
#### 通过工程上技巧
##### Dropout
###### 按定的概率删除部分隐藏神经，激活函数设为o
###### 原因
* 降低对单个神经元的依赖
* 看作不同模型的平均输出
##### Early stopping
###### 迭代次数截断。
###### 缺点：：没有采取不同的方式来解决优化函数损失和过拟合这两个
#### 不直接提供约束的隐式正则化方法
##### 数据集增强
###### 创建假数据并添加到训练集中
###### 概要
##### 采用合适的模型
###### 奥卡姆剃刀法则
* 在假设中，选最简单的
##### 删除冗余特征
## 偏差与方差
### Bias:用很多数据集训练出所有模型的输出平均值与真实模型的输出值的差异
### Variance是不同训练数据集训练出模型之间差异
### 噪声决定了学习的上限
### 概念
#### 学习算法期望预测
##### 公式
#### 方差
##### 刻画了数据扰动造成影响
#### 偏差
##### 期望输出与真实标记的差别
##### 度量了偏离程度，刻画了报合能力
#### 噪声
##### 刻画了学习本身的难度
### 关系
#### 方差为数据扰动，偏差为模型本身
#### 过拟合欠拟合
##### 欠拟合偏差大
##### 过拟合方差大
#### 与复杂度
##### 复杂度过小偏差大
##### 复杂度过大方差大
#### Bagging,boosting
##### Bagging对训练样本采样，再每个数据集训练－ 分类器，取平均，降低方差，与RF类似
##### Boosting:迭代算法，对样本权重调整，降低偏差
#### K折交叉验证
##### 将数据分成K组，做i次验证，k- 1次训练集
### 偏差方差窘境
#### 训练不足，偏差主导，训练过度，方差主导
#### 
## 评估方法
### 混滑矩阵精确率召回率
# 中心主题
